{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfa0385",
   "metadata": {},
   "source": [
    "We are pretty happy with our solution. If possible we'd like to present it in the tutorium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13dc05",
   "metadata": {},
   "source": [
    "Lets import stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b1ed84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b07f5c",
   "metadata": {},
   "source": [
    "First we define the transfer frunction. In this case it is the fermi function which is also called sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba627ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a1d24",
   "metadata": {},
   "source": [
    "Define the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834fdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92971952",
   "metadata": {},
   "source": [
    "Now we define the whole thing needed for the task as class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce281737",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        \"\"\"\n",
    "        Constructor for State.\n",
    "        The class represents a two layer (no hidden layers) densly connected neural Network.\n",
    "\n",
    "        :param in_dim: The amount of input neurons.\n",
    "        :param out_dim: The amount of output neurons.\n",
    "        \"\"\"\n",
    "        # State for backpropagation\n",
    "        self._out = None\n",
    "        self._deriv = None\n",
    "        self._delta_w = None\n",
    "\n",
    "        self._in_dim = in_dim\n",
    "        self._out_dim = out_dim\n",
    "        # Weights for the output layer\n",
    "        # +1 for bias\n",
    "        # The weights shall be between -0.5 and 0.5\n",
    "        self._weights = np.random.rand(self._out_dim, self._in_dim + 1) - 0.5\n",
    "\n",
    "    # TODO this is useless. Remove. Removing this should also reduce allocations by a lot\n",
    "    def reset(self):\n",
    "        self._out = None\n",
    "        self._deriv = None\n",
    "        self._delta_w = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        This function does the forward propagation.\n",
    "\n",
    "        :param input: The input for the NN. A numpy array of dimension ``out_dim`` as given in the constructor.\n",
    "        :return: The outout of the NN. A numpy array of dimension ``out_dim`` as given in the constructor.\n",
    "        \"\"\"\n",
    "        input_with_bias = np.concatenate((input, np.ones(1)))\n",
    "        # Needed for backward\n",
    "        self._input = input_with_bias\n",
    "        net_sum = np.dot(self._weights, input_with_bias)\n",
    "        self._out = sigmoid(net_sum)\n",
    "        self._deriv = self._out * (1 - self._out)\n",
    "\n",
    "        return self._out\n",
    "\n",
    "    def backward(self, expected):\n",
    "        \"\"\"\n",
    "        This function does the backward propagation.\n",
    "        The loss function is the mean squared error.\n",
    "\n",
    "        :param: The expected output for the last input given to ``forward``.\n",
    "        \"\"\"\n",
    "        in_dim_with_bias = self._in_dim + 1\n",
    "        self._delta_w = np.zeros((self._out_dim, in_dim_with_bias))\n",
    "        # Update the weights of perceptron\n",
    "        # TODO use np.indices instead\n",
    "        for i in np.arange(self._out_dim):\n",
    "            self._delta_w[i,:] = learning_rate * (expected[i] - self._out[i]) * self._deriv[i] * self._input\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Updates the weights of the neurons.\n",
    "        Must be called after calling ``forward`` and ``backward``.\n",
    "        \"\"\"\n",
    "        self._weights += self._delta_w\n",
    "        self.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11049176",
   "metadata": {},
   "source": [
    "The task states to load a file that was not uploaded to ecampus. We selected `PA-A_training_data_01.txt` for our code.\n",
    "Since the file is not a proper csv file but we want to use pandas for loading be modified it a bit.\n",
    "Please put the following in `data/PA-A_training_data_01.txt`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb4efea2",
   "metadata": {},
   "source": [
    "# WS22/23_TNN_Assignment_PA-A_data_File_No_1_PA-A_training_data_01.txt\n",
    "# P=4    N=2    M=1   \n",
    "0.0 0.0 0.0\n",
    "0.0 1.0 0.0\n",
    "1.0 0.0 0.0\n",
    "1.0 1.0 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf06292",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94183753",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/PA-A_training_data_01.txt\"\n",
    "df = pd.read_csv(\n",
    "    path,\n",
    "    sep=\" \",\n",
    "    comment=\"#\",\n",
    "    names=[\"in0\", \"in1\", \"out0\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e821f8a",
   "metadata": {},
   "source": [
    "Initialize the class defined above and define an stop condition for the training. (Obviously the no of training steps is not a good criterion but it is okay for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c68e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = State(2, 1)\n",
    "iterations = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e3382",
   "metadata": {},
   "source": [
    "Lets have a look what the network outputs without any training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b596d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58529472]\n",
      "[0.6908783]\n",
      "[0.58529472]\n",
      "[0.58529472]\n"
     ]
    }
   ],
   "source": [
    "print(s.forward(np.array([0,0])))\n",
    "print(s.forward(np.array([0,1])))\n",
    "print(s.forward(np.array([0,0])))\n",
    "print(s.forward(np.array([0,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0895a39",
   "metadata": {},
   "source": [
    "The training loop. We frist get a sample input and the exprected output. Then we do forward propatation, backward porpagation and finally udpate the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8adb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(iterations):\n",
    "# We just repeditly sample from the training set\n",
    "    sample = df.sample()\n",
    "    input = np.array(sample[[\"in0\", \"in1\"]]).squeeze()\n",
    "    output = np.array(sample[\"out0\"])\n",
    "\n",
    "    s.forward(input)\n",
    "    s.backward(output)\n",
    "    s.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets look how the network did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee81132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58529472]\n",
      "[0.6908783]\n",
      "[0.58529472]\n",
      "[0.58529472]\n"
     ]
    }
   ],
   "source": [
    "print(s.forward(np.array([0,0])))\n",
    "print(s.forward(np.array([0,1])))\n",
    "print(s.forward(np.array([0,0])))\n",
    "print(s.forward(np.array([0,0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
